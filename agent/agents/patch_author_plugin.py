from __future__ import annotations

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict

from ..patch_author import PatchAuthor
from ..framework.agent_types import AgentResult, Stage
from ..llm.types import ChatMessage
from ..llm.service import LLMService


@dataclass
class PatchAuthorPlugin:
    id: str = "patch_author"
    stage: Stage = Stage.EDIT
    priority: int = 100

    def __post_init__(self):
        self.agent = PatchAuthor(tool_router=None, run_manager=None)

    def run(self, ctx, request=None) -> AgentResult:
        self.agent.tool_router = ctx.tool_router
        self.agent.run_manager = ctx.run_manager
        llm: LLMService = ctx.services.get("llm") if ctx.services else None
        
        ctx.events.emit(
            "patch_author.enter",
            {
                "has_services": bool(ctx.services),
                "has_llm": bool(llm),
                "provider_name": getattr(getattr(llm, "provider", None), "name", None) if llm else None,
                "model": getattr(llm, "model", None) if llm else None,
            },
        )
        
        if not llm or not llm.enabled():
            ctx.events.emit("llm.skip", {"reason": "LLM provider not configured", "code_path": "no_llm"})
            ctx.events.emit("patch_author.skip", {"reason": "no_llm", "code_path": "no_llm"})
            return AgentResult(status="skip", outputs={"notes": ["LLM æœªé…ç½®ï¼Œè·³è¿‡è‡ªåŠ¨è¡¥ä¸"]})

        ctx.events.emit(
            "patch_author.config",
            {
                "provider": getattr(llm.provider, "name", None),
                "model": getattr(llm, "model", None),
                "timeout": getattr(llm, "timeout", None),
                "base_url_set": bool(getattr(llm.provider, "base_url", None)),
            },
        )

        allowed_files = self._collect_allowed_files(ctx)
        ctx.events.emit("patch_author.allowed_files", {"count": len(allowed_files), "files": allowed_files})

        prompt_msgs = self._build_prompt(ctx, allowed_files)
        if not prompt_msgs:
            ctx.events.emit("patch_author.skip", {"reason": "empty_prompt", "code_path": "no_prompt"})
            return AgentResult(status="skip", outputs={"notes": ["æœªç”Ÿæˆ promptï¼Œè·³è¿‡è‡ªåŠ¨è¡¥ä¸"]})
        
        ctx.events.emit(
            "patch_author.prompt",
            {
                "message_count": len(prompt_msgs),
                "approx_chars": sum(len(m.content) for m in prompt_msgs),
                "files_referenced": self._extract_files_from_context(ctx),
            },
        )

        max_retries = 3
        attempt = 0
        final_edits = None
        last_error = None

        while attempt <= max_retries:
            if attempt > 0:
                ctx.events.emit("patch.retry", {"attempt": attempt, "error": last_error})

            ctx.events.emit(
                "llm.call",
                {"provider": getattr(llm.provider, "name", "unknown"), "model": llm.model, "attempt": attempt},
            )
            ctx.events.emit(
                "llm.request",
                {
                    "provider": getattr(llm.provider, "name", "unknown"),
                    "model": llm.model,
                    "timeout": llm.timeout,
                    "approx_prompt_bytes": sum(len(m.content) for m in prompt_msgs),
                },
            )
            
            resp = llm.generate_patch(prompt_msgs)
            response_text = resp.get("content", "") if isinstance(resp, dict) else ""
            
            ctx.events.emit(
                "llm.response",
                {
                    "ok": resp.get("ok"),
                    "latency_ms": resp.get("latency_ms"),
                    "response_bytes": len(response_text),
                    "error": resp.get("error"),
                },
                level="error" if not resp.get("ok") else "info",
            )

            if not resp.get("ok"):
                # Print debug info when LLM call fails
                print("\n" + "="*80)
                print("âŒ LLM è°ƒç”¨å¤±è´¥")
                print("="*80)
                print(f"é”™è¯¯: {resp.get('error')}")
                if attempt == 0:
                    print(f"\nğŸ“ Prompt (å‰ 1000 å­—ç¬¦):")
                    prompt_preview = "\n".join(m.content for m in prompt_msgs)[:1000]
                    print(prompt_preview)
                print("="*80 + "\n")
                
                ctx.events.emit("patch_author.skip", {"reason": resp.get("error") or "llm_failed", "code_path": "resp_not_ok"})
                return AgentResult(status="skip", outputs={"notes": [f"LLM ç”Ÿæˆå¤±è´¥: {resp.get('error')}"]})

            # Parse JSON edits from response
            edits, parse_error = self._parse_edits(response_text)
            if parse_error:
                # Print debug info when parsing fails
                print("\n" + "="*80)
                print("âŒ JSON è§£æå¤±è´¥")
                print("="*80)
                print(f"é”™è¯¯: {parse_error}")
                print(f"\nğŸ“¥ æ¨¡å‹è¿”å›å†…å®¹ (å‰ 2000 å­—ç¬¦):")
                print(response_text[:2000])
                print("="*80 + "\n")
                
                ctx.events.emit("patch.parse_fail", {"error": parse_error})
                if attempt < max_retries:
                    prompt_msgs.append(ChatMessage(
                        role="user",
                        content=f"ä½ çš„è¾“å‡ºæ— æ³•è§£æä¸º JSONï¼Œé”™è¯¯ï¼š{parse_error}ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ– markdown æ ‡è®°ã€‚å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªç¼–è¾‘å¯¹è±¡ã€‚",
                    ))
                    attempt += 1
                    last_error = parse_error
                    continue
                else:
                    ctx.events.emit("patch_author.skip", {"reason": "parse_fail_after_retry", "code_path": "parse_fail"})
                    return AgentResult(status="skip", outputs={"notes": [f"æ— æ³•è§£æ LLM è¾“å‡º: {parse_error}"]})

            # Validate edits
            if not edits:
                err_msg = "LLM è¾“å‡ºä¸ºç©ºæ•°ç»„ï¼Œè¯·ç”Ÿæˆè‡³å°‘ä¸€ä¸ªç¼–è¾‘æŒ‡ä»¤"
                print("\n" + "="*80)
                print("âŒ ç¼–è¾‘æŒ‡ä»¤éªŒè¯å¤±è´¥")
                print("="*80)
                print(f"é”™è¯¯: {err_msg}")
                print("="*80 + "\n")
                
                ctx.events.emit("patch.verify.fail", {"error": err_msg})
                last_error = err_msg
                if attempt < max_retries:
                    prompt_msgs.append(ChatMessage(
                        role="user",
                        content=f"{err_msg}ã€‚è¯·ç”Ÿæˆè‡³å°‘ä¸€ä¸ªåŒ…å« file_path/search_block/replace_block çš„å¯¹è±¡ã€‚",
                    ))
                    attempt += 1
                else:
                    ctx.events.emit("patch.apply.final_fail", {"error": err_msg})
                    return AgentResult(status="skip", outputs={"notes": [err_msg]})
                continue

            ctx.events.emit("patch.verify.start", {"edit_count": len(edits)})
            is_valid, err_msg = self._validate_edits(ctx, edits, allowed_files)
            
            if is_valid:
                ctx.events.emit("patch.verify.success", {"edit_count": len(edits)})
                final_edits = edits
                break
            else:
                # Print debug info when validation fails
                print("\n" + "="*80)
                print("âŒ ç¼–è¾‘æŒ‡ä»¤éªŒè¯å¤±è´¥")
                print("="*80)
                print(f"é”™è¯¯: {err_msg}")
                print(f"\nğŸ“‹ ç”Ÿæˆçš„ç¼–è¾‘æŒ‡ä»¤ (å…± {len(edits)} ä¸ª):")
                import json
                print(json.dumps(edits, indent=2, ensure_ascii=False)[:1500])
                print("="*80 + "\n")
                
                ctx.events.emit("patch.verify.fail", {"error": err_msg})
                last_error = err_msg
                if attempt < max_retries:
                    prompt_msgs.append(ChatMessage(
                        role="user",
                        content=f"ä½ çš„ Search & Replace æŒ‡ä»¤æ— æ³•åº”ç”¨ï¼Œé”™è¯¯ï¼š\n{err_msg}\nè¯·æ£€æŸ¥ search_block æ˜¯å¦å®Œå…¨åŒ¹é…æ–‡ä»¶å†…å®¹ï¼ˆåŒ…æ‹¬ç©ºæ ¼å’Œæ¢è¡Œï¼‰ï¼Œå¹¶é‡æ–°ç”Ÿæˆã€‚",
                    ))
                    attempt += 1
                else:
                    ctx.events.emit("patch.apply.final_fail", {"error": err_msg})
                    return AgentResult(status="skip", outputs={"notes": [f"ç¼–è¾‘æŒ‡ä»¤æ— æ³•åº”ç”¨: {err_msg}"]})

        # Save edits to JSON file
        edit_path = ctx.run_manager.save_patch(ctx, 1, json.dumps(final_edits, indent=2, ensure_ascii=False))
        ctx.patch_queue.append(str(edit_path))
        
        ctx.events.emit("patch.proposed", {"count": len(final_edits), "artifacts": [str(edit_path)]})
        return AgentResult(status="ok", artifacts=[str(edit_path)], outputs={"edits": final_edits})

    def _build_prompt(self, ctx, allowed_files: list[str]) -> list[ChatMessage]:
        system = (
            "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ä»£ç ä¿®å¤åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ç”Ÿæˆ Search & Replace æŒ‡ä»¤æ¥ä¿®æ”¹ä»£ç ã€‚\n"
            "è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯çº¯ JSON æ•°ç»„ï¼ˆä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼‰ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š\n"
            "- file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¿…é¡»åœ¨ ALLOWED_FILES ä¸­ï¼‰\n"
            "- search_block: è¦æœç´¢çš„ä»£ç å—ï¼ˆå¿…é¡»å®Œå…¨åŒ¹é…æ–‡ä»¶å†…å®¹ï¼ŒåŒ…æ‹¬ç©ºæ ¼å’Œæ¢è¡Œï¼‰\n"
            "- replace_block: æ›¿æ¢åçš„ä»£ç å—\n"
            "æ³¨æ„ï¼šsearch_block å¿…é¡»åœ¨æ–‡ä»¶ä¸­å”¯ä¸€å­˜åœ¨ï¼Œå¦åˆ™æ— æ³•åº”ç”¨ã€‚\n"
            "ç¤ºä¾‹è¾“å‡ºï¼š\n"
            '[\n'
            '  {\n'
            '    "file_path": "demo_c_project/src/calculator.c",\n'
            '    "search_block": "int add(int a, int b) {\\n    return a + b;\\n}",\n'
            '    "replace_block": "int add(int a, int b) {\\n    return a + b;\\n}\\n\\nint mod(int a, int b) {\\n    return a % b;\\n}"\n'
            '  }\n'
            ']'
        )
        
        user_parts = [
            f"ä»»åŠ¡: {ctx.task}",
            "è¦æ±‚ï¼š",
            "1. è¾“å‡ºçº¯ JSON æ•°ç»„ï¼ˆä¸è¦ä½¿ç”¨ ```json ç­‰ markdown æ ‡è®°ï¼‰",
            "2. search_block å¿…é¡»å®Œå…¨åŒ¹é…æ–‡ä»¶å†…å®¹",
            "3. ä¿æŒæœ€å°æ”¹åŠ¨",
            "4. åªä¿®æ”¹å¿…è¦çš„æ–‡ä»¶",
            f"ALLOWED_FILES: {allowed_files}",
            "ä»¥ä¸‹æ˜¯ç›®æ ‡æ–‡ä»¶çš„å½“å‰å†…å®¹ï¼Œè¯·åŸºäºæ­¤å†…å®¹ç”Ÿæˆ Search & Replace æŒ‡ä»¤ï¼š"
        ]
        
        for f in allowed_files:
            content = self._read_file_content(ctx, f)
            user_parts.append(f"\n=== File: {f} ===\n{content}\n")

        if ctx.last_build_result and ctx.last_build_result.get('summary'):
            user_parts.append(f"\næ„å»ºé”™è¯¯æ‘˜è¦: {ctx.last_build_result.get('summary')}")
        if ctx.last_test_result and ctx.last_test_result.get('summary'):
            user_parts.append(f"\næµ‹è¯•å¤±è´¥æ‘˜è¦: {ctx.last_test_result.get('summary')}")
        
        user = "\n".join(user_parts)
        return [ChatMessage(role="system", content=system), ChatMessage(role="user", content=user)]

    def _read_file_content(self, ctx, file_path: str) -> str:
        repo_root = Path(getattr(ctx.tool_router, "repo_root", "."))
        full_path = repo_root / file_path
        if not full_path.exists():
            return "[File not found]"
        try:
            with open(full_path, "r", encoding="utf-8", errors="replace") as f:
                lines = f.readlines()
                if len(lines) <= 300:
                    return "".join(lines)
                return "".join(lines[:150]) + "\n... (omitted middle lines) ...\n" + "".join(lines[-150:])
        except Exception as e:
            return f"[Error reading file: {e}]"

    def _parse_edits(self, text: str) -> tuple[list[dict], str]:
        """Parse JSON edits from LLM response, handling markdown code blocks."""
        text = text.strip()
        
        # Remove markdown code blocks if present
        if text.startswith("```"):
            lines = text.split("\n")
            # Remove first line (```json or ```)
            if lines[0].strip().startswith("```"):
                lines = lines[1:]
            # Remove last line if it's ```
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            text = "\n".join(lines).strip()
        
        try:
            edits = json.loads(text)
            if not isinstance(edits, list):
                return None, "è¾“å‡ºå¿…é¡»æ˜¯ JSON æ•°ç»„"
            for i, edit in enumerate(edits):
                if not isinstance(edit, dict):
                    return None, f"ç¬¬ {i+1} ä¸ªå…ƒç´ ä¸æ˜¯ JSON å¯¹è±¡"
                if "file_path" not in edit:
                    return None, f"ç¬¬ {i+1} ä¸ªå…ƒç´ ç¼ºå°‘ file_path"
                if "search_block" not in edit:
                    return None, f"ç¬¬ {i+1} ä¸ªå…ƒç´ ç¼ºå°‘ search_block"
                if "replace_block" not in edit:
                    return None, f"ç¬¬ {i+1} ä¸ªå…ƒç´ ç¼ºå°‘ replace_block"
            return edits, None
        except json.JSONDecodeError as e:
            return None, f"JSON è§£æå¤±è´¥: {e}"

    def _validate_edits(self, ctx, edits: list[dict], allowed_files: list[str]) -> tuple[bool, str]:
        """Validate that all edits can be applied."""
        repo_root = Path(getattr(ctx.tool_router, "repo_root", "."))
        allowed_set = set(allowed_files)
        
        for i, edit in enumerate(edits):
            file_path = edit["file_path"]
            search_block = edit["search_block"]
            
            # Check if file is allowed
            if file_path not in allowed_set:
                return False, f"æ–‡ä»¶ {file_path} ä¸åœ¨ ALLOWED_FILES ä¸­"
            
            # Check if file exists
            full_path = repo_root / file_path
            if not full_path.exists():
                return False, f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨"
            
            # Check if search_block exists in file
            try:
                with open(full_path, "r", encoding="utf-8", errors="replace") as f:
                    content = f.read()
                
                if search_block not in content:
                    return False, f"åœ¨æ–‡ä»¶ {file_path} ä¸­æ‰¾ä¸åˆ° search_blockï¼ˆç¬¬ {i+1} ä¸ªç¼–è¾‘ï¼‰"
                
                # Check if search_block is unique
                if content.count(search_block) > 1:
                    return False, f"åœ¨æ–‡ä»¶ {file_path} ä¸­ search_block å‡ºç°å¤šæ¬¡ï¼ˆç¬¬ {i+1} ä¸ªç¼–è¾‘ï¼‰ï¼Œæ— æ³•ç¡®å®šæ›¿æ¢ä½ç½®"
                    
            except Exception as e:
                return False, f"è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}"
        
        return True, ""

    def _collect_allowed_files(self, ctx) -> list[str]:
        files = []
        if ctx.context_pack:
            for item in ctx.context_pack.get("files", []):
                if isinstance(item, dict):
                    for m in item.get("matches", []):
                        path = m.split(":", 1)[0]
                        if path and path not in files:
                            files.append(path)
        if not files:
            files = [
                "demo_c_project/include/calculator.h",
                "demo_c_project/src/calculator.c",
                "demo_c_project/tests/test_calculator.cpp",
            ]
        return files[:10]

    def _extract_files_from_context(self, ctx) -> list:
        files = []
        if ctx.context_pack:
            for item in ctx.context_pack.get("files", []):
                if isinstance(item, dict):
                    matches = item.get("matches", [])
                    if matches:
                        files.append(matches[0].split(":")[0])
        return files[:10]
